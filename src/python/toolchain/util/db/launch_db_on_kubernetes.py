#!/usr/bin/env ./python
# Copyright 2019 Toolchain Labs, Inc. All rights reserved.
# Licensed under the Apache License, Version 2.0 (see LICENSE).

from __future__ import annotations

import asyncio
import copy
import logging
import re
import subprocess
import time
from argparse import ArgumentParser, Namespace
from collections.abc import Sequence
from contextlib import asynccontextmanager

from toolchain.base.password import generate_password
from toolchain.base.toolchain_binary import ToolchainBinary
from toolchain.base.toolchain_error import ToolchainAssertion, ToolchainError
from toolchain.kubernetes.application_api import KubernetesApplicationAPI
from toolchain.kubernetes.constants import KubernetesCluster
from toolchain.kubernetes.secret_api import SecretAPI
from toolchain.kubernetes.volume_api import VolumeAPI
from toolchain.util.db.db_secrets import DatabaseSecretsHelper, SimpleDatabaseSecretsHelper
from toolchain.util.db.init_db import DbInitializer
from toolchain.util.prod.helm_charts import RemoteHelmChart
from toolchain.util.prod.helm_client import HelmClient

logger = logging.getLogger(__name__)


class LaunchDbOnKubernetes(ToolchainBinary):
    """Launch a db instance on the Kubernetes cluster currently pointed to by the local kubectl."""

    CHART = "postgresql"
    CHART_REPO = "bitnami"
    # https://github.com/bitnami/charts/blob/main/bitnami/postgresql/Chart.yaml
    POSTGRESQL_CHART_VERSION = "12.1.9"

    def __init__(self, cmd_args: Namespace) -> None:
        super().__init__(cmd_args)
        logger.info(f"LaunchDbOnKubernetes arguments: {cmd_args}")
        self._release_name = cmd_args.release_name
        # Note: Do not change this persistent volume claim name - it reflects the one generated by the postgresql chart.
        self._persistent_volume_claim_name = f"data-{self._release_name}-postgresql-0"
        self._namespace = cmd_args.namespace
        # Currently the postgresql helm chart doesn't properly support non-standard ports (even though
        # it thinks it does). If that support works properly in the future we might want to set the port
        # in a cmd-line flag. Until then we hard-code the standard port here.
        self._port = "5432"
        self._dbs = cmd_args.db or []
        self._simple_dbs = cmd_args.simple_db
        self._storage_gb = cmd_args.storage_gb
        self._namespace = cmd_args.namespace
        self._helm = HelmClient(aws_region=cmd_args.aws_region, cluster=HelmClient.Cluster.DEV)
        self._helm.check_cluster_connectivity()
        self._master_password_secret_name = f"{self._release_name}-postgresql"

    def run(self) -> int:
        password = self.upgrade_install()
        self.init_helm_db_release(password)
        logger.info("Done!")
        return 0

    def upgrade_install(self) -> str:
        """Assumes the caller has the `helm` cli set up to point to the right Kubernetes cluster."""
        password, password_key = self._get_master_password()  # Password from existing release (if there is any)
        logger.info(
            f"Install helm chart {self.CHART_REPO}/{self.CHART} to release {self._release_name} in namespace {self._namespace}"
        )
        size = f"{self._storage_gb}Gi"
        values = {
            "volumePermissions": {"enabled": True},
            "auth": {
                "existingSecret": self._master_password_secret_name,
                "secretKeys": {"adminPasswordKey": password_key},
            },
            "primary": {
                "service": {"ports": {"postgresql": self._port}},
                "persistence": {"size": size},
                "nodeSelector": {"toolchain.instance_category": "database"},
            },
            "readReplicas": {"nodeSelector": {"toolchain.instance_category": "database"}},
        }
        if self._persistent_volume_claim_exists():
            # If the pvc exists, reuse it so we retain the data.
            logger.info(f"Reusing existing PersistentVolumeClaim {self._persistent_volume_claim_name}")
            values["primary"]["persistence"]["existingClaim"] = self._persistent_volume_claim_name  # type: ignore[index]
        else:
            # Otherwise let the chart create a new one.
            logger.info(f"No existing PersistentVolumeClaim {self._persistent_volume_claim_name} found. Creating one.")
        chart = RemoteHelmChart(name=self.CHART, version=self.POSTGRESQL_CHART_VERSION)
        self._helm.refresh_repos()
        self._helm.upgrade_install_from_repo(
            release_name=self._release_name,
            namespace=self._namespace,
            chart=chart,
            values=values,
            repo=self.CHART_REPO,
            wait_for_ready=False,
        )
        logger.info("Database release creation complete.")
        return password

    def init_helm_db_release(self, password: str) -> None:
        asyncio.run(self._do_init_helm_db_release(password))
        logger.info("Initialization complete.")

    def _persistent_volume_claim_exists(self) -> bool:
        api = VolumeAPI.for_cluster(cluster=self._helm.cluster, namespace=self._namespace)
        return api.persistent_volume_claim_exists(self._persistent_volume_claim_name)

    def _get_secrets_api(self) -> SecretAPI:
        return SecretAPI.for_cluster(namespace=self._namespace, cluster=self._helm.cluster)

    async def _do_init_helm_db_release(self, password: str):
        secrets = DatabaseSecretsHelper.for_kubernetes(namespace=self._namespace, cluster=self._helm.cluster)
        master_creds = self._get_master_creds(password)
        secrets.store_db_creds(f"{self._release_name}-master-creds", master_creds)
        pod_name = self._get_running_pod_name()
        # Postgres takes a few seconds to start up the first time, and unfortunately the pod declares itself
        # ready before this startup is complete.  So we wait to give the service a reasonable chance to actually
        # be ready. Note that, unfortunately, we can't poll for readiness, because, for whatever reason,
        # Postgres restarts itself shortly after startup.  We might get a successful ready poll before this
        # restart, and then have subsequent requests fail during the restart.
        time.sleep(6)
        async with self._port_forward(pod_name) as port:
            port_forwarded_master_creds = copy.copy(master_creds)
            port_forwarded_master_creds.update(
                original_host=master_creds["host"], original_port=master_creds["port"], host="127.0.0.1", port=port
            )
            if self._simple_dbs:
                self._init_simple_dbs(port_forwarded_master_creds, simple_dbs=self._simple_dbs)
            initializer = DbInitializer(secrets, master_creds=port_forwarded_master_creds)
            for db in self._dbs:
                # Init the db.
                initializer = DbInitializer(secrets, master_creds=port_forwarded_master_creds)
                initializer.init_db(self._release_name, db)
                logger.info(f"Database {db} initialized.")

    def _init_simple_dbs(self, master_creds: dict, simple_dbs: Sequence[str]) -> None:
        secrets_helper = SimpleDatabaseSecretsHelper.for_kubernetes(
            cluster=self._helm.cluster, namespaces=(self._namespace,)
        )
        initializer = DbInitializer(secrets_helper, master_creds=master_creds)
        for simple_db_name in simple_dbs:
            secret_name = initializer.init_db_simple(db_release_name=self._release_name, db_name=simple_db_name)
            logger.info(f"Simple Database {simple_db_name} initialized, password stored in {secret_name}.")

    @asynccontextmanager
    async def _port_forward(self, pod_name: str):
        # Pattern that matches the output line that tells us what the local port is.
        _port_forward_output_re = re.compile(r"Forwarding from 127.0.0.1:(?P<local_port>\d+) -> " + self._port)

        cmd = [
            "kubectl",
            "--namespace",
            self._namespace,
            "port-forward",
            pod_name,
            f":{self._port}",
            "--context",
            KubernetesCluster.DEV.value,
        ]
        logger.info(f"Forwarding a local port to pod {pod_name}")
        proc = await asyncio.create_subprocess_exec(*cmd, stdout=subprocess.PIPE)
        try:
            # Scan the output until we match the output line containing the local port.
            async for line in proc.stdout:  # type: ignore[union-attr]
                mo = _port_forward_output_re.search(line.decode())
                if mo:
                    local_port = int(mo.group("local_port"))
                    logger.info(f"Forwarding from 127.0.0.1:{local_port} -> {pod_name}:{self._port}")
                    yield local_port
                    return
        finally:
            logger.info("Destroying port forwarding.")
            proc.kill()
            await proc.wait()

    def _get_running_pod_name(self):
        """Returns the name of some ready pod in the release."""
        api = KubernetesApplicationAPI.for_cluster(cluster=HelmClient.Cluster.DEV, namespace=self._namespace)
        labels = {"app.kubernetes.io/instance": self._release_name, "app.kubernetes.io/name": "postgresql"}

        def get_pod_status() -> str | None:
            pod = api.get_pod_info_with_labels(**labels)
            logger.info(f"Waiting for pod to reach Running phase. (release={self._release_name}) {pod!r}")
            return pod.name if pod and pod.is_running else None

        try:
            logger.info("Waiting for pod to reach Running phase.")
            pod_name = self._wait_and_retry(get_pod_status, sleep_time=4)
            logger.info(f"Found pod in phase Running: {pod_name}")
            return pod_name
        except self.RetryException:
            raise ToolchainAssertion(f"Couldn't find a ready pod in release {self._release_name}")

    def _get_master_password(self) -> tuple[str, str]:
        # The chart's password secret wasn't written by us, so we need a raw SecretAPI to access it.
        secret_api = self._get_secrets_api()
        password_secret = secret_api.get_secret(self._master_password_secret_name) or {}
        if not password_secret:
            password = generate_password()
            logger.info(f"Create password secert in: {self._master_password_secret_name}")
            secret_api.set_secret(
                secret_name=self._master_password_secret_name, value_dict={"postgres-password": password}
            )
            return password, "postgres-password"

        logger.info(f"Loading existing password secret from {self._master_password_secret_name}")
        if "postgres-password" in password_secret:
            return password_secret["postgres-password"].decode(), "postgres-password"
        if "postgresql-password" in password_secret:
            return password_secret["postgresql-password"].decode(), "postgresql-password"
        raise ToolchainAssertion(
            f"Can't find password key in existing secret: {self._master_password_secret_name} keys: {password_secret.keys()}"
        )

    def _get_master_creds(self, password: str) -> dict[str, str | int | None]:
        """Gets the initial master creds for a db deployed from the postgresql helm chart."""
        return {
            "engine": "postgres",
            "user": "postgres",
            "password": password,
            "set_role": None,
            "host": f"{self._release_name}-postgresql.{self._namespace}",
            "port": self._port,
            "dbname": "postgres",
        }

    class RetryException(ToolchainError):
        pass

    @classmethod
    def _wait_and_retry(cls, callback, n=30, sleep_time=0.5, backoff=1.1) -> None:
        """Retry callback n times, sleeping between tries.

        If the callback returns None, it'll be retried.
        If the callback returns non-None, that value will be returned by this method.
        If the callback raises, the exception will not be handled by this method.

        :raises RetryException: if all retries failed.
        """
        while n:
            ret = callback()
            if ret is not None:
                return ret
            n -= 1
            sleep_time *= backoff
            time.sleep(sleep_time)
        raise cls.RetryException()

    @classmethod
    def add_arguments(cls, parser: ArgumentParser) -> None:
        cls.add_aws_region_argument(parser)
        parser.add_argument("--release-name", metavar="name", required=True, help="The name to give the db release.")
        parser.add_argument(
            "--namespace", metavar="namespace", required=True, help="The namespace to create the db in."
        )
        parser.add_argument(
            "--db",
            metavar="<db_name>",
            action="append",
            help="Names of logical databases to create in the db instance.  "
            "Each db will have a corresponding owner role and login role.",
        )
        parser.add_argument(
            "--simple-db",
            metavar="<simple_db_name>",
            action="append",
            help="Names of logical databases to create in the db instance, simple DBs are created without role and with a non-rotatable json secret.",
        )
        parser.add_argument("--storage-gb", type=int, default=1, help="Storage size in GB.")


if __name__ == "__main__":
    LaunchDbOnKubernetes.start()
